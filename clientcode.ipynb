{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install all required libraries\n",
        "!pip install scikit-learn flwr qiskit numpy pandas matplotlib joblib pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecyrE394GZz4",
        "outputId": "0f7225a0-a8ac-48e2-df45-b04e6bdf0228"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: flwr in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.39.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: cryptography<43.0.0,>=42.0.4 in /usr/local/lib/python3.10/dist-packages (from flwr) (42.0.8)\n",
            "Requirement already satisfied: grpcio!=1.64.2,<2.0.0,<=1.64.3,>=1.60.0 in /usr/local/lib/python3.10/dist-packages (from flwr) (1.64.3)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from flwr) (0.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from flwr) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.25.2 in /usr/local/lib/python3.10/dist-packages (from flwr) (4.25.5)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from flwr) (3.21.0)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.10/dist-packages (from flwr) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from flwr) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from flwr) (1.1.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.10/dist-packages (from flwr) (0.12.5)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.7.0)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.39 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.39.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43.0.0,>=42.0.4->flwr) (1.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.5.0->flwr) (2.18.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.5->flwr) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.5->flwr) (1.5.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2FWbUKbFWWD",
        "outputId": "9c7a8d1a-9b73-467e-bac0-ec24353a2375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1: Starting...\n",
            "Client 1: No Global Model Found. Training Fresh Model...\n",
            "Loading training dataset...\n",
            "Loading preprocessed training data...\n",
            "Preprocessed training data saved!\n",
            "Loading testing dataset...\n",
            "Loading preprocessed training data...\n",
            "Preprocessed testing data saved!\n",
            "Client 1: Epoch 1 - Training...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib\n",
        "import os\n",
        "import pennylane as qml\n",
        "import random\n",
        "import base64\n",
        "from cryptography.fernet import Fernet\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------------------- Configuration --------------------\n",
        "ROLE = \"client\"  # Change to \"server\" when running on the server\n",
        "CLIENT_ID = 1  # Unique ID for the client\n",
        "DATASET_PATH = \"client_1_dataset.csv\"\n",
        "TEST_DATASET_PATH = \"client_2_dataset.csv\"  # Path to your testing datasetjbvubdiubvdbvsyubvsuyvvbxsuyvuivuifvtuivctuvu\n",
        "SERVER_MODEL_PATH = \"server_global_model.joblib\"\n",
        "LOCAL_MODEL_PATH = f\"client_{CLIENT_ID}_model_encrypted.joblib\"\n",
        "ENCRYPTION_KEY_PATH = \"encryption_key.key\"\n",
        "DECRYPTED_MODEL_PATH = f\"client_{CLIENT_ID}_model_decrypted.joblib\"\n",
        "NOISE_LEVEL = 0.001  # Quantum noise level\n",
        "NUM_QUBITS = 4\n",
        "\n",
        "# Quantum Device\n",
        "dev = qml.device(\"default.mixed\", wires=NUM_QUBITS)\n",
        "\n",
        "# -------------------- Quantum Differential Privacy --------------------\n",
        "@qml.qnode(dev)\n",
        "def quantum_noise(weights):\n",
        "    \"\"\"Simulate quantum noise.\"\"\"\n",
        "    for i in range(NUM_QUBITS):\n",
        "        qml.RX(weights[i], wires=i)\n",
        "        qml.RY(weights[i], wires=i)\n",
        "    qml.DepolarizingChannel(NOISE_LEVEL, wires=0)\n",
        "    qml.PhaseDamping(NOISE_LEVEL, wires=1)\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(NUM_QUBITS)]\n",
        "\n",
        "def apply_qdp(gradients):\n",
        "    \"\"\"Apply Quantum Differential Privacy.\"\"\"\n",
        "    noisy_gradients = []\n",
        "    for grad in gradients:\n",
        "        weights = np.random.rand(NUM_QUBITS)\n",
        "        noise = sum(quantum_noise(weights)) / NUM_QUBITS\n",
        "        noisy_gradients.append(grad + noise)\n",
        "    return np.array(noisy_gradients)\n",
        "\n",
        "# -------------------- Encryption Utilities --------------------\n",
        "def load_or_create_key():\n",
        "    if os.path.exists(ENCRYPTION_KEY_PATH):\n",
        "        with open(ENCRYPTION_KEY_PATH, \"rb\") as file:\n",
        "            return file.read()\n",
        "    else:\n",
        "        key = Fernet.generate_key()\n",
        "        with open(ENCRYPTION_KEY_PATH, \"wb\") as file:\n",
        "            file.write(key)\n",
        "        return key\n",
        "\n",
        "def encrypt_model(model_path, encrypted_path, key):\n",
        "    \"\"\"Encrypt the model file.\"\"\"\n",
        "    fernet = Fernet(key)\n",
        "    with open(model_path, \"rb\") as file:\n",
        "        encrypted_data = fernet.encrypt(file.read())\n",
        "    with open(encrypted_path, \"wb\") as file:\n",
        "        file.write(encrypted_data)\n",
        "\n",
        "def decrypt_model(encrypted_path, decrypted_path, key):\n",
        "    \"\"\"Decrypt the model file.\"\"\"\n",
        "    fernet = Fernet(key)\n",
        "    with open(encrypted_path, \"rb\") as file:\n",
        "        decrypted_data = fernet.decrypt(file.read())\n",
        "    with open(decrypted_path, \"wb\") as file:\n",
        "        file.write(decrypted_data)\n",
        "\n",
        "# -------------------- Load and Preprocess Data --------------------\n",
        "def load_and_preprocess_data(train=True):\n",
        "    \"\"\"\n",
        "    Load and preprocess data.\n",
        "    If train=True, load the training dataset. Else, load the testing dataset.\n",
        "    \"\"\"\n",
        "    processed_file = \"preprocessed_data_train.joblib\" if train else \"preprocessed_data_test.joblib\"\n",
        "    dataset_path = DATASET_PATH if train else TEST_DATASET_PATH\n",
        "\n",
        "    if os.path.exists(processed_file):\n",
        "        print(f\"Loading preprocessed {'training' if train else 'testing'} data...\")\n",
        "        data = joblib.load(processed_file)\n",
        "        return data[\"X\"], data[\"y\"]\n",
        "\n",
        "    # Load the dataset\n",
        "    print(f\"Loading {'training' if train else 'testing'} dataset...\")\n",
        "    df = pd.read_csv(dataset_path)\n",
        "\n",
        "    # Drop forbidden and irrelevant columns\n",
        "    df = df.drop(columns=['oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'], errors='ignore')\n",
        "    df = df.drop(columns=['nameOrig', 'nameDest'], errors='ignore')\n",
        "\n",
        "    # One-Hot Encoding\n",
        "    df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy=\"mean\")\n",
        "    df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "    # Binary target column\n",
        "    df_imputed['isFraud'] = df_imputed['isFraud'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "    # Features and target\n",
        "    X = df_imputed.drop(columns=['isFraud'])\n",
        "    y = df_imputed['isFraud']\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Save preprocessed data\n",
        "    joblib.dump({\"X\": X_scaled, \"y\": y}, processed_file)\n",
        "    print(f\"Preprocessed {'training' if train else 'testing'} data saved!\")\n",
        "\n",
        "    return X_scaled, y\n",
        "\n",
        "# -------------------- Client Node --------------------\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "def client_node():\n",
        "    print(f\"Client {CLIENT_ID}: Starting...\")\n",
        "    global_model_exists = os.path.exists(SERVER_MODEL_PATH)\n",
        "\n",
        "    if global_model_exists:\n",
        "        print(f\"Client {CLIENT_ID}: Loading Global Model from Server...\")\n",
        "        global_model = joblib.load(SERVER_MODEL_PATH)\n",
        "    else:\n",
        "        print(f\"Client {CLIENT_ID}: No Global Model Found. Training Fresh Model...\")\n",
        "        global_model = None\n",
        "\n",
        "    # Load and preprocess training data\n",
        "    print(\"Loading training dataset...\")\n",
        "    X_train, y_train = load_and_preprocess_data()\n",
        "    joblib.dump({\"X\": X_train, \"y\": y_train}, \"train_data_preprocessed.joblib\")\n",
        "    print(\"Preprocessed training data saved!\")\n",
        "\n",
        "    # Load and preprocess testing data\n",
        "    print(\"Loading testing dataset...\")\n",
        "    TEST_DATASET_PATH = \"test_dataset.csv\"  # Path to the testing dataset\n",
        "    X_test, y_test = load_and_preprocess_data()\n",
        "    joblib.dump({\"X\": X_test, \"y\": y_test}, \"test_data_preprocessed.joblib\")\n",
        "    print(\"Preprocessed testing data saved!\")\n",
        "\n",
        "    # Initialize or load the model\n",
        "    model = RandomForestClassifier(n_estimators=10, warm_start=True, random_state=42)\n",
        "\n",
        "    # Training Loop with Epochs\n",
        "    num_epochs = 5\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"Client {CLIENT_ID}: Epoch {epoch} - Training...\")\n",
        "\n",
        "        # Incrementally train the model\n",
        "        model.set_params(n_estimators=epoch * 10)  # Add 10 trees per epoch\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate the model on the training dataset\n",
        "        y_pred_train = model.predict(X_train)\n",
        "        accuracy = accuracy_score(y_train, y_pred_train)\n",
        "        precision = precision_score(y_train, y_pred_train)\n",
        "        recall = recall_score(y_train, y_pred_train)\n",
        "        f1 = f1_score(y_train, y_pred_train)\n",
        "\n",
        "        # Print performance metrics\n",
        "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Final Test on the Testing Dataset\n",
        "    print(\"Client {CLIENT_ID}: Testing Local Model...\")\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    print(f\"Client {CLIENT_ID}: Final Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Save the model\n",
        "    joblib.dump(model, LOCAL_MODEL_PATH)\n",
        "    print(f\"Client {CLIENT_ID}: Local Model Saved Successfully!\")\n",
        "\n",
        "# -------------------- Server Node --------------------\n",
        "def server_node():\n",
        "    key = load_or_create_key()\n",
        "    print(\"Server: Starting Aggregation...\")\n",
        "    models = []\n",
        "    for client_id in range(1, 4):  # Assume 3 clients\n",
        "        encrypted_model_path = f\"client_{client_id}_model_encrypted.joblib\"\n",
        "        if os.path.exists(encrypted_model_path):\n",
        "            decrypt_model(encrypted_model_path, DECRYPTED_MODEL_PATH, key)\n",
        "            model = joblib.load(DECRYPTED_MODEL_PATH)\n",
        "            models.append(model)\n",
        "            print(f\"Server: Model from Client {client_id} Loaded.\")\n",
        "    if not models:\n",
        "        print(\"Server: No models found!\")\n",
        "        return\n",
        "\n",
        "    # Aggregate models\n",
        "    avg_importances = np.mean([model.feature_importances_ for model in models], axis=0)\n",
        "    global_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    global_model.fit(np.zeros((10, len(avg_importances))), np.zeros(10))  # Dummy data\n",
        "    global_model.feature_importances_ = avg_importances\n",
        "\n",
        "    # Save global model\n",
        "    joblib.dump(global_model, SERVER_MODEL_PATH)\n",
        "    encrypt_model(SERVER_MODEL_PATH, SERVER_MODEL_PATH, key)\n",
        "    print(\"Server: Global Model Aggregated and Saved.\")\n",
        "\n",
        "# -------------------- Execution --------------------\n",
        "if ROLE == \"client\":\n",
        "    client_node()\n",
        "elif ROLE == \"server\":\n",
        "    server_node()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import joblib\n",
        "import os\n",
        "import pennylane as qml\n",
        "import random\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------------------- Configuration --------------------\n",
        "ROLE = \"client\"  # Change to \"server\" when running on the server\n",
        "CLIENT_ID = 1  # Unique ID for the client\n",
        "DATASET_PATH = \"client_1_dataset.csv\"\n",
        "TEST_DATASET_PATH = \"client_2_dataset.csv\"  # Path to your testing dataset\n",
        "SERVER_MODEL_PATH = \"server_global_model.joblib\"\n",
        "LOCAL_MODEL_PATH = f\"client_{CLIENT_ID}_model.joblib\"  # No encryption for local model\n",
        "NOISE_LEVEL = 0.001  # Quantum noise level\n",
        "NUM_QUBITS = 4\n",
        "\n",
        "# Quantum Device\n",
        "dev = qml.device(\"default.mixed\", wires=NUM_QUBITS)\n",
        "\n",
        "# -------------------- Quantum Differential Privacy --------------------\n",
        "@qml.qnode(dev)\n",
        "def quantum_noise(weights):\n",
        "    \"\"\"Simulate quantum noise.\"\"\"\n",
        "    for i in range(NUM_QUBITS):\n",
        "        qml.RX(weights[i], wires=i)\n",
        "        qml.RY(weights[i], wires=i)\n",
        "    qml.DepolarizingChannel(NOISE_LEVEL, wires=0)\n",
        "    qml.PhaseDamping(NOISE_LEVEL, wires=1)\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(NUM_QUBITS)]\n",
        "\n",
        "def apply_qdp(gradients):\n",
        "    \"\"\"Apply Quantum Differential Privacy.\"\"\"\n",
        "    noisy_gradients = []\n",
        "    for grad in gradients:\n",
        "        weights = np.random.rand(NUM_QUBITS)\n",
        "        noise = sum(quantum_noise(weights)) / NUM_QUBITS\n",
        "        noisy_gradients.append(grad + noise)\n",
        "    return np.array(noisy_gradients)\n",
        "\n",
        "# -------------------- Load and Preprocess Data --------------------\n",
        "def load_and_preprocess_data(train=True):\n",
        "    \"\"\"\n",
        "    Load and preprocess data.\n",
        "    If train=True, load the training dataset. Else, load the testing dataset.\n",
        "    \"\"\"\n",
        "    processed_file = \"preprocessed_data_train.joblib\" if train else \"preprocessed_data_test.joblib\"\n",
        "    dataset_path = DATASET_PATH if train else TEST_DATASET_PATH\n",
        "\n",
        "    if os.path.exists(processed_file):\n",
        "        print(f\"Loading preprocessed {'training' if train else 'testing'} data...\")\n",
        "        data = joblib.load(processed_file)\n",
        "        return data[\"X\"], data[\"y\"]\n",
        "\n",
        "    # Load the dataset\n",
        "    print(f\"Loading {'training' if train else 'testing'} dataset...\")\n",
        "    df = pd.read_csv(dataset_path)\n",
        "\n",
        "    # Drop forbidden and irrelevant columns\n",
        "    df = df.drop(columns=['oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest'], errors='ignore')\n",
        "    df = df.drop(columns=['nameOrig', 'nameDest'], errors='ignore')\n",
        "\n",
        "    # One-Hot Encoding\n",
        "    df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy=\"mean\")\n",
        "    df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "    # Binary target column\n",
        "    df_imputed['isFraud'] = df_imputed['isFraud'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "    # Features and target\n",
        "    X = df_imputed.drop(columns=['isFraud'])\n",
        "    y = df_imputed['isFraud']\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Save preprocessed data\n",
        "    joblib.dump({\"X\": X_scaled, \"y\": y}, processed_file)\n",
        "    print(f\"Preprocessed {'training' if train else 'testing'} data saved!\")\n",
        "\n",
        "    return X_scaled, y\n",
        "\n",
        "# -------------------- Client Node --------------------\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm  # For progress bar\n",
        "\n",
        "def client_node():\n",
        "    print(f\"Client {CLIENT_ID}: Starting...\")\n",
        "    global_model_exists = os.path.exists(SERVER_MODEL_PATH)\n",
        "\n",
        "    if global_model_exists:\n",
        "        print(f\"Client {CLIENT_ID}: Loading Global Model from Server...\")\n",
        "        global_model = joblib.load(SERVER_MODEL_PATH)\n",
        "    else:\n",
        "        print(f\"Client {CLIENT_ID}: No Global Model Found. Training Fresh Model...\")\n",
        "        global_model = None\n",
        "\n",
        "    # Load and preprocess training data\n",
        "    print(\"Loading training dataset...\")\n",
        "    X_train, y_train = load_and_preprocess_data()\n",
        "    joblib.dump({\"X\": X_train, \"y\": y_train}, \"train_data_preprocessed.joblib\")\n",
        "    print(\"Preprocessed training data saved!\")\n",
        "\n",
        "    # Load and preprocess testing data\n",
        "    print(\"Loading testing dataset...\")\n",
        "    TEST_DATASET_PATH = \"test_dataset.csv\"  # Path to the testing dataset\n",
        "    X_test, y_test = load_and_preprocess_data()\n",
        "    joblib.dump({\"X\": X_test, \"y\": y_test}, \"test_data_preprocessed.joblib\")\n",
        "    print(\"Preprocessed testing data saved!\")\n",
        "\n",
        "    # Initialize or load the model\n",
        "    model = RandomForestClassifier(n_estimators=10, warm_start=True, random_state=42)\n",
        "\n",
        "    # Training Loop with Epochs\n",
        "    num_epochs = 5\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"Client {CLIENT_ID}: Epoch {epoch} - Training...\")\n",
        "\n",
        "        # Incrementally train the model\n",
        "        model.set_params(n_estimators=epoch * 10)  # Add 10 trees per epoch\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate the model on the training dataset\n",
        "        y_pred_train = model.predict(X_train)\n",
        "        accuracy = accuracy_score(y_train, y_pred_train)\n",
        "        precision = precision_score(y_train, y_pred_train)\n",
        "        recall = recall_score(y_train, y_pred_train)\n",
        "        f1 = f1_score(y_train, y_pred_train)\n",
        "\n",
        "        # Print performance metrics\n",
        "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Final Test on the Testing Dataset\n",
        "    print(\"Client {CLIENT_ID}: Testing Local Model...\")\n",
        "    y_pred_test = model.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    print(f\"Client {CLIENT_ID}: Final Testing Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Save the model\n",
        "    joblib.dump(model, LOCAL_MODEL_PATH)\n",
        "    print(f\"Client {CLIENT_ID}: Local Model Saved Successfully!\")\n",
        "\n",
        "# -------------------- Server Node --------------------\n",
        "def server_node():\n",
        "    print(\"Server: Starting Aggregation...\")\n",
        "    models = []\n",
        "    for client_id in range(1, 4):  # Assume 3 clients\n",
        "        model_path = f\"client_{client_id}_model.joblib\"\n",
        "        if os.path.exists(model_path):\n",
        "            model = joblib.load(model_path)\n",
        "            models.append(model)\n",
        "            print(f\"Server: Model from Client {client_id} Loaded.\")\n",
        "\n",
        "    if not models:\n",
        "        print(\"Server: No models found!\")\n",
        "        return\n",
        "\n",
        "    # Aggregate models\n",
        "    avg_importances = np.mean([model.feature_importances_ for model in models], axis=0)\n",
        "    global_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    global_model.fit(np.zeros((10, len(avg_importances))), np.zeros(10))  # Dummy data\n",
        "    global_model.feature_importances_ = avg_importances\n",
        "\n",
        "    # Save global model\n",
        "    joblib.dump(global_model, SERVER_MODEL_PATH)\n",
        "    print(\"Server: Global Model Aggregated and Saved.\")\n",
        "\n",
        "# -------------------- Execution --------------------\n",
        "if ROLE == \"client\":\n",
        "    client_node()\n",
        "elif ROLE == \"server\":\n",
        "    server_node()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf1xIysTs8Q7",
        "outputId": "9ee9936b-b1eb-4002-f056-db6bb0dd4b70"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1: Starting...\n",
            "Client 1: No Global Model Found. Training Fresh Model...\n",
            "Loading training dataset...\n",
            "Loading preprocessed training data...\n",
            "Preprocessed training data saved!\n",
            "Loading testing dataset...\n",
            "Loading preprocessed training data...\n",
            "Preprocessed testing data saved!\n",
            "Client 1: Epoch 1 - Training...\n",
            "Accuracy: 0.9998, Precision: 0.9987, Recall: 0.8346, F1 Score: 0.9093\n",
            "Client 1: Epoch 2 - Training...\n",
            "Accuracy: 0.9999, Precision: 1.0000, Recall: 0.9130, F1 Score: 0.9545\n",
            "Client 1: Epoch 3 - Training...\n",
            "Accuracy: 0.9999, Precision: 1.0000, Recall: 0.9554, F1 Score: 0.9772\n",
            "Client 1: Epoch 4 - Training...\n",
            "Accuracy: 1.0000, Precision: 1.0000, Recall: 0.9719, F1 Score: 0.9857\n",
            "Client 1: Epoch 5 - Training...\n",
            "Accuracy: 1.0000, Precision: 1.0000, Recall: 0.9835, F1 Score: 0.9917\n",
            "Client {CLIENT_ID}: Testing Local Model...\n",
            "Client 1: Final Testing Accuracy: 1.0000\n",
            "Client 1: Local Model Saved Successfully!\n"
          ]
        }
      ]
    }
  ]
}